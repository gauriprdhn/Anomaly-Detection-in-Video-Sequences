{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7LUPIIlwZ9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt1x1n2kweKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet import nd ,gluon, autograd,gpu\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "from scipy import signal\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "API_RBels874",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DRIVE_MOUNT='/content/gdrive'\n",
        "drive.mount(DRIVE_MOUNT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6OvEphWhEsO",
        "colab_type": "text"
      },
      "source": [
        "#### **1. CAE:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWbBD4gphO0I",
        "colab_type": "text"
      },
      "source": [
        "**1.1 Training Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxowNKv3zElu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UCSD_FOLDER=os.path.join(DRIVE_MOUNT, 'My Drive', 'UCSD_Anomaly_Dataset.v1p2')\n",
        "train_files = sorted(glob.glob(UCSD_FOLDER+ '/UCSDped1/Train/*/*'))\n",
        "train_images = np.zeros((len(train_files),1,100,100))\n",
        "for idx, filename in enumerate(train_files):\n",
        "    im = Image.open(filename)\n",
        "    im = im.resize((100,100))\n",
        "    train_images[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "np.save(UCSD_FOLDER+ '/UCSD_Anomaly_Dataset.v1p2.npy',train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FwuAeVgzGAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvolutionalAutoencoder(gluon.nn.HybridBlock):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(ConvolutionalAutoencoder, self).__init__()\n",
        "        \n",
        "        with self.name_scope():\n",
        "            self.encoder = gluon.nn.HybridSequential()\n",
        "            with self.encoder.name_scope():\n",
        "                self.encoder.add(gluon.nn.Conv2D(32, 5, activation='relu'))\n",
        "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
        "                self.encoder.add(gluon.nn.Conv2D(32, 5, activation='relu'))\n",
        "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
        "                self.encoder.add(gluon.nn.Dense(2000))\n",
        "\n",
        "            self.decoder = gluon.nn.HybridSequential()\n",
        "            with self.decoder.name_scope():\n",
        "                self.decoder.add(gluon.nn.Dense(32*22*22, activation='relu'))\n",
        "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
        "                self.decoder.add(gluon.nn.Conv2DTranspose(32, 5, activation='relu'))\n",
        "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
        "                self.decoder.add(gluon.nn.Conv2DTranspose(1, kernel_size=5, activation='sigmoid'))\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder[0](x)\n",
        "        x = x.reshape((-1,32,22,22))\n",
        "#         print(self.decoder)\n",
        "        x = self.decoder[1](x)\n",
        "        x = self.decoder[2](x)\n",
        "        x = self.decoder[3](x)\n",
        "        x = self.decoder[4](x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ka06DKTgYlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_train = np.load(UCSD_FOLDER+ '/UCSD_Anomaly_Dataset.v1p2.npy')\n",
        "batch_size= 32\n",
        "dataset = gluon.data.ArrayDataset(mx.nd.array(im_train, dtype=np.float32))\n",
        "dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch='rollover',shuffle=True)\n",
        "ctx = gpu()\n",
        "num_epochs = 50\n",
        "model = ConvolutionalAutoencoder()\n",
        "model.hybridize()\n",
        "model.collect_params().initialize(mx.init.Xavier('gaussian'), ctx=ctx)\n",
        "loss_function = gluon.loss.L2Loss()\n",
        "optimizer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 1e-4, 'wd': 1e-5})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V193mDtNzili",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Training Loop ##\n",
        "loss_train=[]\n",
        "for epoch in range(num_epochs):\n",
        "    for image_batch in dataloader:   \n",
        "        image = image_batch.as_in_context(ctx)\n",
        "        with mx.autograd.record():\n",
        "            output = model(image)\n",
        "            loss = loss_function(output, image)\n",
        "        loss.backward()\n",
        "        optimizer.step(image.shape[0])\n",
        "    loss_train.append(mx.nd.mean(loss).asscalar())\n",
        "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, mx.nd.mean(loss).asscalar()))\n",
        "## Saving model parameters ##\n",
        "model.save_parameters(UCSD_FOLDER+ \"/autoencoder_ucsd.params\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNPIrNh_uwmZ",
        "colab": {}
      },
      "source": [
        "np.save(UCSD_FOLDER+'/loss_train_cae.npy',np.array(loss_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAu90H15hSrV",
        "colab_type": "text"
      },
      "source": [
        "**1.2 Testing Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qw__3KIwqHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_file = sorted(glob.glob(UCSD_FOLDER +'/UCSDped1/Test/Test024/*'))\n",
        "test_file_gt = sorted(glob.glob(UCSD_FOLDER +'/UCSDped1/Test/Test024_gt/*'))\n",
        "a = np.zeros((len(test_file_gt),2,100,100))\n",
        "for idx,filename in enumerate(test_file):\n",
        "    im = Image.open(filename)\n",
        "    im = im.resize((100,100))\n",
        "    a[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "\n",
        "for idx,filename in enumerate(test_file_gt):\n",
        "    im = Image.open(filename)\n",
        "    im = im.resize((100,100))\n",
        "    a[idx,1,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "\n",
        "dataset = gluon.data.ArrayDataset(mx.nd.array(a, dtype=np.float32))\n",
        "dataloader = gluon.data.DataLoader(dataset, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3b6blc0h158",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_regularity_score(model,dataloader):\n",
        "  \"\"\"\n",
        "  Calculated regularity score per frame:\n",
        "  Regularity Score = 1 - (e_t - min@t(e_t))/max@t(e_t)\n",
        "  where e_t = sum over pixelwise l2 loss for each frame\n",
        "  \"\"\"\n",
        "  e_t = []\n",
        "  for image in dataloader:\n",
        "    img = image[:,0,:,:].reshape(1,1,image.shape[-2],image.shape[-1])\n",
        "    img = img.as_in_context(mx.gpu())\n",
        "    output = model(img)\n",
        "    output = (output.asnumpy().squeeze()*255).reshape(100*100,1)\n",
        "    img = (img.asnumpy().squeeze()*255).reshape(100*100,1)\n",
        "    e_xyt = np.linalg.norm(output-img,axis=1,ord=2)\n",
        "    e_t.append(np.sum(e_xyt))\n",
        "  e_t_min = min(e_t)\n",
        "  e_t_max = max(e_t)\n",
        "  reg_scores = []\n",
        "  for i in range(len(e_t)):\n",
        "    reg_scores.append(1 - ((e_t[i]-e_t_min)/e_t_max))\n",
        "  return reg_scores\n",
        "\n",
        "model =  ConvolutionalAutoencoder()\n",
        "model.load_parameters(UCSD_FOLDER+ \"/autoencoder_ucsd.params\",ctx=ctx)\n",
        "reg_scores_cae = plot_regularity_score(model,dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su3m5f9SziDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_anomaly(img, output, diff, H, threshold, counter,UCSD_FOLDER):\n",
        "  \"\"\"\n",
        "  Plots the images along the axis to show the input, output of the model,\n",
        "  difference between the 2, and their predicted anomalies as red dots on\n",
        "  the input image.\n",
        "  \"\"\"\n",
        "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
        "    ax0.set_axis_off()\n",
        "    ax1.set_axis_off()\n",
        "    ax2.set_axis_off()\n",
        "    ax0.set_title('input image')\n",
        "    ax1.set_title('reconstructed image')\n",
        "    ax2.set_title('diff ')\n",
        "    ax3.set_title('anomalies')\n",
        "    ax0.imshow(img, cmap=plt.cm.gray, interpolation='nearest') \n",
        "    ax1.imshow(output, cmap=plt.cm.gray, interpolation='nearest')   \n",
        "    ax2.imshow(diff, cmap=plt.cm.viridis, vmin=0, vmax=255, interpolation='nearest')  \n",
        "    ax3.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
        "    x,y = np.where(H > threshold)\n",
        "    ax3.scatter(y,x,color='red',s=0.1) \n",
        "    plt.axis('off')\n",
        "    fig.savefig(UCSD_FOLDER+'/images/' + str(counter) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG_G-pqW2Qs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_evaluation(model,dataloader):\n",
        "  loss_l2_per_frame = []\n",
        "  threshold = 4*255\n",
        "  counter = 0\n",
        "  test_loss_metric = gluon.loss.SigmoidBCELoss()\n",
        "  loss_per_frame = 0\n",
        "  im_list = []\n",
        "  i = 0\n",
        "  for image in dataloader:\n",
        "    counter = counter + 1\n",
        "    img = image[:,0,:,:].reshape(1,1,image.shape[-2],image.shape[-1])\n",
        "    mask = image[:,1,:,:].as_in_context(mx.gpu())\n",
        "    img = img.as_in_context(mx.gpu())\n",
        "    output = model(img)\n",
        "    output = output.transpose((0,2,3,1))\n",
        "    img = img.transpose((0,2,3,1))\n",
        "    output = output.asnumpy()*255\n",
        "    img = img.asnumpy()*255\n",
        "    diff = np.abs(output-img) \n",
        "    tmp = diff[0,:,:,0]\n",
        "    H = signal.convolve2d(tmp, np.ones((4,4)), mode='same')\n",
        "    H_new = mx.nd.array(np.where(H>threshold,1,0).reshape((1,100,100)),ctx=gpu())\n",
        "    loss = test_loss_metric(H_new, mask)\n",
        "    loss_l2_per_frame.append(loss.asscalar())\n",
        "    plot_anomaly(img[0,:,:,0], output[0,:,:,0], diff[0,:,:,0], H, threshold, counter,UCSD_FOLDER)\n",
        "\n",
        "  print(\"Total loss per frame for anomalies predicted = \",sum(loss_l2_per_frame)/len(dataloader))\n",
        "\n",
        "## Evaluating the model using the anomaly predictions and regularity scores\n",
        "model_evaluation(model,dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Qry_MDxaSq",
        "colab_type": "text"
      },
      "source": [
        "Saving images as video file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NrETBPi_R9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Saving the output plots as video depicting anomalies ##\n",
        "import cv2\n",
        "out_im = sorted(glob.glob(UCSD_FOLDER+ '/images/*.png'))\n",
        "\n",
        "img_array = []\n",
        "for filename in out_im:\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, layers = img.shape\n",
        "    # size = (width,height)\n",
        "    img_array.append(img)\n",
        "\n",
        "size = (360, 720)\n",
        "_name = UCSD_FOLDER+'/vid' + '.mp4'\n",
        "# self._cap = VideoCapture(0)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "out_vid = cv2.VideoWriter(_name,fourcc,15,size)\n",
        "\n",
        "for i in range(0,199):\n",
        "  out_vid.write(img_array[i])\n",
        "\n",
        "out_vid.release()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suH0TYlL2HMX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### **2. Spatio- Temporal Layer Stacked CAE:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JUvAC_6hkzx",
        "colab_type": "text"
      },
      "source": [
        "**2.1 Training Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mSLzeUrjKtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = sorted(glob.glob(UCSD_FOLDER+'/UCSDped1/Train/*/*'))\n",
        "train_images = np.zeros((int(len(files)/n), n, 227, 227))\n",
        "i = 0\n",
        "idx = 0\n",
        "for filename in range(0, len(files)):\n",
        "    im = Image.open(files[filename])\n",
        "    im = im.resize((n,n))\n",
        "    a[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "    i = i + 1\n",
        "    if i >= n:\n",
        "      idx = idx + 1\n",
        "      i = 0\n",
        "np.save(UCSD_FOLDER + '/stacked_cae.npy',train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhx4D_Bm18r6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class convSTAE(gluon.nn.HybridBlock):\n",
        "    def __init__(self):\n",
        "        super(convSTAE, self).__init__()\n",
        "        with self.name_scope():\n",
        "            self.encoder = gluon.nn.HybridSequential(prefix=\"encoder\")\n",
        "            with self.encoder.name_scope():\n",
        "                self.encoder.add(gluon.nn.Conv2D(512, kernel_size=15, strides=4, activation='relu'))\n",
        "                self.encoder.add(gluon.nn.BatchNorm())\n",
        "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
        "                self.encoder.add(gluon.nn.BatchNorm())\n",
        "                self.encoder.add(gluon.nn.Conv2D(256, kernel_size=4, activation='relu'))\n",
        "                self.encoder.add(gluon.nn.BatchNorm())\n",
        "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
        "                self.encoder.add(gluon.nn.BatchNorm())\n",
        "                self.encoder.add(gluon.nn.Conv2D(128, kernel_size=3, activation='relu'))\n",
        "                self.encoder.add(gluon.nn.BatchNorm())\n",
        "                \n",
        "            self.decoder = gluon.nn.HybridSequential(prefix=\"decoder\")\n",
        "            with self.decoder.name_scope():\n",
        "                self.decoder.add(gluon.nn.Conv2DTranspose(channels=256, kernel_size=3, activation='relu'))\n",
        "                self.decoder.add(gluon.nn.BatchNorm())\n",
        "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
        "                self.decoder.add(gluon.nn.BatchNorm())\n",
        "                self.decoder.add(gluon.nn.Conv2DTranspose(channels=512, kernel_size=4, activation='relu'))\n",
        "                self.decoder.add(gluon.nn.BatchNorm())\n",
        "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
        "                self.decoder.add(gluon.nn.BatchNorm())\n",
        "                self.decoder.add(gluon.nn.Conv2DTranspose(channels=10, kernel_size=15, strides=4, activation='sigmoid'))\n",
        "\n",
        "\n",
        "    def hybrid_forward(self, F, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kLXe37MG9U_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx = gpu()\n",
        "im_train = np.load(UCSD_FOLDER + '/stacked_cae.npy')\n",
        "batch_size=32\n",
        "dataset = gluon.data.ArrayDataset(mx.nd.array(im_train, dtype=np.float32))\n",
        "dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch='rollover',shuffle=True)\n",
        "num_epochs = 50\n",
        "model = convSTAE()\n",
        "model.hybridize()\n",
        "model.collect_params().initialize(mx.init.Xavier('gaussian'), ctx=ctx)\n",
        "loss_function = gluon.loss.L2Loss()\n",
        "optimizer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 1e-4, 'wd': 1e-5})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whNGfrj1HTFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Training Loop ##\n",
        "loss_train_stacked=[]\n",
        "for epoch in range(num_epochs): \n",
        "    for image_batch in dataloader:\n",
        "        image = image_batch.as_in_context(ctx)\n",
        "        with mx.autograd.record():\n",
        "            output = model(image)\n",
        "            loss = loss_function(output, image)\n",
        "        loss.backward()\n",
        "        optimizer.step(image.shape[0])\n",
        "    loss_train_stacked.append(mx.nd.mean(loss).asscalar())\n",
        "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, mx.nd.mean(loss).asscalar()))\n",
        "## Saving model params ##\n",
        "model.save_parameters(UCSD_FOLDER+ \"/autoencoder_stacked_ucsd.params\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th89dlyrKywD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(UCSD_FOLDER+'/loss_train_stacked.npy',loss_train_stacked)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkHvIgVChoWU",
        "colab_type": "text"
      },
      "source": [
        "**2.2 Testing Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6mJpnMchnqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  convSTAE()\n",
        "model.load_parameters(UCSD_FOLDER +'/autoencoder_stacked_ucsd.params',ctx=ctx)\n",
        "batch_size= 1\n",
        "n=10 \n",
        "test_file = sorted(glob.glob(UCSD_FOLDER+ '/UCSDped1/Test/Test024/*'))\n",
        "test_file_gt = sorted(glob.glob(UCSD_FOLDER+'/UCSDped1/Test/Test024_gt/*'))\n",
        "a = np.zeros((int(len(test_file)/n), n, 227, 227))\n",
        "i = 0\n",
        "idx = 0\n",
        "for filename in range(0, len(test_file)):\n",
        "    im = Image.open(test_file[filename])\n",
        "    im = im.resize((227,227))\n",
        "    a[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "    i = i + 1\n",
        "    if i >= n:\n",
        "      idx = idx + 1\n",
        "      i = 0\n",
        "\n",
        "b = np.zeros((int(len(test_file_gt)/n), n, 227, 227))\n",
        "i = 0\n",
        "idx = 0\n",
        "\n",
        "for filename in range(0, len(test_file_gt)):\n",
        "    im = Image.open(test_file_gt[filename])\n",
        "    im = im.resize((227,227))\n",
        "    b[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "    i = i + 1\n",
        "    if i >= n:\n",
        "      idx = idx + 1\n",
        "      i = 0\n",
        "## Test-time dataloaders for true images and their anomaly masks ##\n",
        "dataset = gluon.data.ArrayDataset(mx.nd.array(a,ctx= ctx,dtype=np.float32))\n",
        "dataloader = gluon.data.DataLoader(dataset, batch_size=1)\n",
        "test_dataset = gluon.data.ArrayDataset(mx.nd.array(b,ctx= ctx, dtype=np.float32))\n",
        "test_dataloader = gluon.data.DataLoader(dataset, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d_27nq2hu4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_anomaly(img, output, diff, H, threshold, counter,UCSD_FOLDER):\n",
        "  \n",
        "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
        "    ax0.set_axis_off()\n",
        "    ax1.set_axis_off()\n",
        "    ax2.set_axis_off()\n",
        "    \n",
        "    ax0.set_title('input image')\n",
        "    ax1.set_title('reconstructed image')\n",
        "    ax2.set_title('diff ')\n",
        "    ax3.set_title('anomalies')\n",
        "    ax0.imshow(img, cmap=plt.cm.gray, interpolation='nearest') \n",
        "    ax1.imshow(output, cmap=plt.cm.gray, interpolation='nearest')   \n",
        "    ax2.imshow(diff, cmap=plt.cm.viridis, vmin=0, vmax=255, interpolation='nearest')  \n",
        "    ax3.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
        "    x,y = np.where(H > threshold)\n",
        "    ax3.scatter(y,x,color='red',s=0.1) \n",
        "    plt.axis('off')   \n",
        "    fig.savefig('/content/gdrive/My Drive/UCSD_Anomaly_Dataset.v1p2/images_stacked_cae/' + str(counter) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BwROFkfiHV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_compute(output,image_gt,image,UCSD_FOLDER,counter):\n",
        "  loss_l2_per_frame = []\n",
        "  test_loss_metric = gluon.loss.SigmoidBCELoss(from_sigmoid=False)\n",
        "  # there will be 10 chnannels rep each image flatten them out\n",
        "  output = output.asnumpy().squeeze()*255\n",
        "  image_gt= image_gt.asnumpy().squeeze()\n",
        "  image= image.asnumpy().squeeze()*255\n",
        "  threshold = 4*255\n",
        "  for i in range(0,10):\n",
        "    counter+=1\n",
        "    im_out = output[i,:,:]\n",
        "    im = image[i,:,:]\n",
        "    diff = np.abs(im_out-im)\n",
        "    H = signal.convolve2d(diff, np.ones((4,4)), mode='same')\n",
        "    H_new = mx.nd.array(np.where(H>threshold,1,0).reshape((1,227,227)),ctx=gpu())\n",
        "    mask =  mx.nd.array(image_gt[i,:,:].reshape((1,227,227)),ctx=gpu())\n",
        "    loss_l2_per_frame.append(test_loss_metric(H_new,mask).asscalar())\n",
        "    plot_anomaly(im, im_out,diff, H, threshold, counter,UCSD_FOLDER)\n",
        "  return loss_l2_per_frame\n",
        "\n",
        "def model_evaluation(model,dataloader,test_dataloader,UCSD_FOLDER):\n",
        "  loss = []\n",
        "  im_list = []\n",
        "  counter = 0\n",
        "  for image,image_gt in zip(dataloader,test_dataloader):\n",
        "    output = model(image)\n",
        "    l = loss_compute(output,image_gt,image,UCSD_FOLDER,counter)\n",
        "    counter+=10\n",
        "    loss.extend(l)\n",
        "  print(\"Total loss per frame for anomalies predicted = \",sum(loss)/len(loss))\n",
        "\n",
        "model_evaluation(model,dataloader,test_dataloader,UCSD_FOLDER)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQDEvxIx4wiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_evaluation(model,dataloader,test_dataloader,UCSD_FOLDER):\n",
        "  loss = []\n",
        "  im_list = []\n",
        "  counter = 0\n",
        "  for image,image_gt in zip(dataloader,test_dataloader):\n",
        "    output = model(image)\n",
        "    l = loss_compute(output,image_gt,image,UCSD_FOLDER,counter)\n",
        "    counter+=10\n",
        "    loss.extend(l)\n",
        "  print(\"Total loss per frame for anomalies predicted = \",sum(loss)/len(loss))\n",
        "\n",
        "model_evaluation(model,dataloader,test_dataloader,UCSD_FOLDER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjI-vJzVxjVE",
        "colab_type": "text"
      },
      "source": [
        "Saving images as video file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHSllYMVxhul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "images = sorted(glob.glob(UCSD_FOLDER+'/images_stacked_cae/*.png'))\n",
        "img_array = []\n",
        "for filename in images:\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, layers = img.shape\n",
        "    img_array.append(img)\n",
        "file_name = UCSD_FOLDER+'/vid_cae.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "size = (1024,720)\n",
        "out_vid = cv2.VideoWriter(file_name,fourcc,1,size,3)\n",
        "for i in range(0,199):\n",
        "  frame = cv2.resize(img_array[i],size)\n",
        "  out_vid.write(frame)\n",
        "out_vid.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqW656hh2qaI",
        "colab_type": "text"
      },
      "source": [
        "#### **3. LSTM-Based Stacked CAE:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MbCiGAbwHMP",
        "colab_type": "text"
      },
      "source": [
        "**3.1 Training Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwtFNQUZ2u8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = sorted(glob.glob(UCSD_FOLDER+'/UCSDped1/Train/*/*'))\n",
        "train_images = np.zeros((int(len(files)/n), n, 227, 227))\n",
        "i = 0\n",
        "idx = 0\n",
        "for filename in range(0, len(files)):\n",
        "    im = Image.open(files[filename])\n",
        "    im = im.resize((n,n))\n",
        "    a[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "    i = i + 1\n",
        "    if i >= n:\n",
        "      idx = idx + 1\n",
        "      i = 0\n",
        "np.save(UCSD_FOLDER + '/stacked_cae.npy',train_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llpusjeVLXlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvLSTMAE(gluon.nn.HybridBlock):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(ConvLSTMAE, self).__init__(**kwargs)\n",
        "        with self.name_scope():\n",
        "\n",
        "          self.encoder = gluon.nn.HybridSequential()\n",
        "          self.encoder.add(gluon.nn.Conv2D(128, kernel_size=11, strides=4, activation='relu'))\n",
        "          self.encoder.add(gluon.nn.Conv2D(64, kernel_size=5, strides=2, activation='relu'))\n",
        "\n",
        "          self.temporal_encoder = gluon.rnn.HybridSequentialRNNCell()\n",
        "          self.temporal_encoder.add(gluon.contrib.rnn.Conv2DLSTMCell((64,26,26), 64, 3, 3, i2h_pad=1))\n",
        "          self.temporal_encoder.add(gluon.contrib.rnn.Conv2DLSTMCell((64,26,26), 32, 3, 3, i2h_pad=1))\n",
        "          self.temporal_encoder.add(gluon.contrib.rnn.Conv2DLSTMCell((32,26,26), 64, 3, 3, i2h_pad=1))\n",
        "\n",
        "          self.decoder =  gluon.nn.HybridSequential()\n",
        "          self.decoder.add(gluon.nn.Conv2DTranspose(channels=128, kernel_size=5, strides=2, activation='relu'))\n",
        "          self.decoder.add(gluon.nn.Conv2DTranspose(channels=10, kernel_size=11, strides=4, activation='sigmoid'))\n",
        "\n",
        "    def hybrid_forward(self, F, x, states=None, **kwargs):\n",
        "        x = self.encoder(x)\n",
        "        x, states = self.temporal_encoder(x, states)\n",
        "        x = self.decoder(x)\n",
        "\n",
        "        return x, states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS4UjJ1B6Rdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=8\n",
        "dataset = gluon.data.ArrayDataset(mx.nd.array(im_train, dtype=np.float32))\n",
        "dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch='rollover',shuffle=True)\n",
        "model = ConvLSTMAE()\n",
        "ctx = gpu()\n",
        "num_epochs = 50\n",
        "model.hybridize()\n",
        "model.collect_params().initialize(mx.init.Xavier(), ctx=mx.gpu())\n",
        "loss_function = gluon.loss.L2Loss()\n",
        "optimizer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 1e-4, 'wd': 1e-5})\n",
        "states = model.temporal_encoder.begin_state(batch_size=batch_size, ctx=ctx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQD6O4B3LpB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train_lstm=[]\n",
        "for epoch in range(num_epochs):\n",
        "    for image_batch in dataloader:   \n",
        "        image = image_batch.as_in_context(ctx)\n",
        "        with mx.autograd.record():\n",
        "            output,states = model(image,states)\n",
        "            output = mx.nd.array(output,ctx=gpu())\n",
        "            loss = loss_function(output, image)\n",
        "        loss.backward()\n",
        "        optimizer.step(image.shape[0])\n",
        "    loss_train_lstm.append(mx.nd.mean(loss).asscalar())\n",
        "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, mx.nd.mean(loss).asscalar()))\n",
        "\n",
        "model.save_parameters(UCSD_FOLDER+ \"/autoencoder_lstm_ucsd.params\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wuHIZF7M_wE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(UCSD_FOLDER+'/loss_train_lstm.npy',loss_train_lstm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kiu_wYiDwD1u",
        "colab_type": "text"
      },
      "source": [
        "**3.2 Testing Phase:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyz2G0ixVtwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  ConvLSTMAE()\n",
        "model.load_parameters(UCSD_FOLDER +'/autoencoder_lstm_ucsd.params',ctx=ctx)\n",
        "batch_size= 1\n",
        "n=10 \n",
        "test_file = sorted(glob.glob(UCSD_FOLDER+ '/UCSDped1/Test/Test024/*'))\n",
        "test_file_gt = sorted(glob.glob(UCSD_FOLDER+'/UCSDped1/Test/Test024_gt/*'))\n",
        "a = np.zeros((int(len(test_file)/n), n, 227, 227))\n",
        "i = 0\n",
        "idx = 0\n",
        "for filename in range(0, len(test_file)):\n",
        "    im = Image.open(test_file[filename])\n",
        "    im = im.resize((227,227))\n",
        "    a[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "    i = i + 1\n",
        "    if i >= n:\n",
        "      idx = idx + 1\n",
        "      i = 0\n",
        "\n",
        "b = np.zeros((int(len(test_file_gt)/n), n, 227, 227))\n",
        "i = 0\n",
        "idx = 0\n",
        "\n",
        "for filename in range(0, len(test_file_gt)):\n",
        "    im = Image.open(test_file_gt[filename])\n",
        "    im = im.resize((227,227))\n",
        "    b[idx,i,:,:] = np.array(im, dtype=np.float32)/255.0\n",
        "    i = i + 1\n",
        "    if i >= n:\n",
        "      idx = idx + 1\n",
        "      i = 0\n",
        "## Test-time dataloaders for true images and their anomaly masks ##\n",
        "dataset = gluon.data.ArrayDataset(mx.nd.array(a,ctx= ctx,dtype=np.float32))\n",
        "dataloader = gluon.data.DataLoader(dataset, batch_size=1)\n",
        "test_dataset = gluon.data.ArrayDataset(mx.nd.array(b,ctx= ctx, dtype=np.float32))\n",
        "test_dataloader = gluon.data.DataLoader(dataset, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPF2zXHcn8nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_anomaly(img, output, diff, H, threshold, counter,UCSD_FOLDER):\n",
        "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
        "    ax0.set_axis_off()\n",
        "    ax1.set_axis_off()\n",
        "    ax2.set_axis_off()\n",
        "    ax0.set_title('input image')\n",
        "    ax1.set_title('reconstructed image')\n",
        "    ax2.set_title('diff ')\n",
        "    ax3.set_title('anomalies')\n",
        "    ax0.imshow(img, cmap=plt.cm.gray, interpolation='nearest') \n",
        "    ax1.imshow(output, cmap=plt.cm.gray, interpolation='nearest')   \n",
        "    ax2.imshow(diff, cmap=plt.cm.viridis, vmin=0, vmax=255, interpolation='nearest')  \n",
        "    ax3.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
        "    x,y = np.where(H > threshold)\n",
        "    ax3.scatter(y,x,color='red',s=0.1) \n",
        "    plt.axis('off')   \n",
        "    fig.savefig('/content/gdrive/My Drive/UCSD_Anomaly_Dataset.v1p2/images_stacked_lstm/' + str(counter) + '.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nz0DUIFx6Eib",
        "colab": {}
      },
      "source": [
        "def loss_compute(output,image_gt,image,UCSD_FOLDER,counter):\n",
        "  loss_l2_per_frame = []\n",
        "  test_loss_metric = gluon.loss.SigmoidBCELoss(from_sigmoid=False)\n",
        "  # there will be 10 chnannels rep each image flatten them out\n",
        "  output = output.asnumpy().squeeze()*255\n",
        "  image_gt= image_gt.asnumpy().squeeze()\n",
        "  image= image.asnumpy().squeeze()*255\n",
        "  threshold = 4*255\n",
        "  for i in range(0,10):\n",
        "    counter+=1\n",
        "    im_out = output[i,:,:]\n",
        "    im = image[i,:,:]\n",
        "    diff = np.abs(im_out-im)\n",
        "    H = signal.convolve2d(diff, np.ones((4,4)), mode='same')\n",
        "    H_new = mx.nd.array(np.where(H>threshold,1,0).reshape((1,227,227)),ctx=gpu())\n",
        "    mask =  mx.nd.array(image_gt[i,:,:].reshape((1,227,227)),ctx=gpu())\n",
        "    loss_l2_per_frame.append(test_loss_metric(H_new,mask).asscalar())\n",
        "    plot_anomaly(im, im_out,diff, H, threshold, counter,UCSD_FOLDER)\n",
        "  return loss_l2_per_frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTs4Q4T34rkN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_evaluation(model,dataloader,test_dataloader,UCSD_FOLDER,states):\n",
        "  counter = 0\n",
        "  loss = []\n",
        "  im_list = []\n",
        "  i = 0\n",
        "  for image,image_gt in zip(dataloader,test_dataloader):\n",
        "    output,_ = model(image,states)\n",
        "    l = loss_compute(output,image_gt,image,UCSD_FOLDER,counter)\n",
        "    counter+=10\n",
        "    loss.extend(l)\n",
        "  print(\"Total loss per frame for anomalies predicted = \",sum(loss)/len(loss))\n",
        "\n",
        "## Evaluating the model using the anomaly predictions and regularity scores\n",
        "states = model.temporal_encoder.begin_state(batch_size=batch_size, ctx=ctx)\n",
        "model_evaluation(model,dataloader,test_dataloader,UCSD_FOLDER,states)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_IGRAfuxO5r",
        "colab_type": "text"
      },
      "source": [
        "Saving images as video file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OIyFCOyVpa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "images = sorted(glob.glob('/content/gdrive/My Drive/UCSD_Anomaly_Dataset.v1p2/images_stacked_lstm/*.png'))\n",
        "img_array = []\n",
        "for filename in images:\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, layers = img.shape\n",
        "    img_array.append(img)\n",
        "file_name = UCSD_FOLDER+'/vid_lstm_cae.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "size = (1024,720)\n",
        "out_vid = cv2.VideoWriter(file_name,fourcc,1,size,3)\n",
        "for i in range(0,199):\n",
        "  frame = cv2.resize(img_array[i],size)\n",
        "  out_vid.write(frame)\n",
        "out_vid.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4-oG1-P8We-",
        "colab_type": "text"
      },
      "source": [
        "#### **4. Regularity Scores Comparison:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uexuHiLExytI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_regularity_score_on_stacked_images(model,dataloader,states=None,lstm=False):\n",
        "  \"\"\"\n",
        "  Calculated regularity score per frame:\n",
        "  Regularity Score = 1 - (e_t - min@t(e_t))/max@t(e_t)\n",
        "  where e_t = sum over pixelwise l2 loss for each frame\n",
        "  \"\"\"\n",
        "  e_t = []\n",
        "  for image in dataloader:\n",
        "    img = image.as_in_context(gpu())\n",
        "    if lstm:\n",
        "      output ,_ = model(img,states)\n",
        "    else:\n",
        "      output = model(img)\n",
        "    output = output.asnumpy().squeeze()*255\n",
        "    img = img.asnumpy().squeeze()*255\n",
        "    for i in range(output.shape[0]):\n",
        "      a = output[i,:,:].reshape(227*227,1)\n",
        "      b = img[i,:,:].reshape(227*227,1)\n",
        "      e_xyt = np.linalg.norm(a-b,axis=1,ord=2)\n",
        "      e_t.append(sum(e_xyt))\n",
        "  e_t_min = min(e_t)\n",
        "  e_t_max = max(e_t)\n",
        "  reg_scores = []\n",
        "  for i in range(len(e_t)):\n",
        "    reg_scores.append(1 - ((e_t[i]-e_t_min)/e_t_max))\n",
        "  return reg_scores\n",
        "\n",
        "model_stcae = convSTAE()\n",
        "model_stcae.load_parameters(UCSD_FOLDER +'/autoencoder_stacked_ucsd.params',ctx=ctx)\n",
        "model_lstm =  ConvLSTMAE()\n",
        "model_lstm.load_parameters(UCSD_FOLDER +'/autoencoder_lstm_ucsd.params',ctx=ctx)\n",
        "reg_scores_stcae = plot_regularity_score_on_stacked_images(model_stcae,dataloader,lstm=False)\n",
        "states = model_lstm.temporal_encoder.begin_state(batch_size=batch_size, ctx=ctx)\n",
        "reg_scores_lstm = plot_regularity_score_on_stacked_images(model_lstm,dataloader,states,lstm=True)\n",
        "## Plots\n",
        "plt.plot(reg_scores_cae,color ='red')\n",
        "plt.plot(reg_scores_stcae,color = 'green')\n",
        "plt.plot(reg_scores_lstm,color='blue')\n",
        "plt.xlabel(\"frame number\")\n",
        "plt.ylabel(\"regularity score\")\n",
        "plt.title( \"Regularity Score per frame\")\n",
        "plt.legend(['CAE','STCAE', 'LSTM-STCAE'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km5PCT9j9kjx",
        "colab_type": "text"
      },
      "source": [
        "#### **5. Training Loss Comparison:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVwxQ-Xt9B_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_train = np.load(UCSD_FOLDER+'/loss_train_cae.npy')\n",
        "loss_train_stacked = np.load(UCSD_FOLDER+'/loss_train_stacked.npy')\n",
        "loss_train_lstm = np.load(UCSD_FOLDER+'/loss_train_lstm.npy')\n",
        "plt.plot(loss_train,'r')\n",
        "plt.plot(loss_train_stacked,'g')\n",
        "plt.plot(loss_train_lstm,'b')\n",
        "plt.title('Training Loss vs Epochs')\n",
        "plt.legend(['CAE','STCAE','LSTM-STCAE'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('reconstruction loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}